{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj9Q5rZAFAlM"
      },
      "source": [
        "Technological Institute of the Philippines | Quezon City - Computer Engineering\n",
        "--- | ---\n",
        "Course Code: | CPE 018\n",
        "Code Title: | Emerging Technologies in CpE 1 - Fundamentals of Computer Vision\n",
        "1st Semester | AY 2023-2024\n",
        "<u>**ACTIVITY NO. 3** | **Basic I/O Scripting, Part 2**\n",
        "**Name** | Villamor, Kurt Russel A\n",
        "**Section** | CPE32S3\n",
        "**Date Performed**: | 02-19-2025\n",
        "**Date Submitted**: | 02-19-2025\n",
        "**Instructor**: | Engr. Roman M. Richard\n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElMxAUPJGYLw"
      },
      "source": [
        "## 1. Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr0bUEs1nxE0"
      },
      "source": [
        "This activity aims to introduce students to OpenCV's I/O Functionality for video processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do-8nSpXFpyd"
      },
      "source": [
        "## 2. Intended Learning Outcomes (ILOs)\n",
        "After this activity, the students should be able to:\n",
        "* Read and write video files using openCV.\n",
        "* Utilize openCV to capture and display images and videos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-RNZovNGV9k"
      },
      "source": [
        "## 3. Procedures and Outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGqUyBbHlhaP"
      },
      "source": [
        "**NOTE:** For this laboratory activity, it is recommended that you download and run the Python notebook on *Spyder IDE*. You must install dependencies by running `!pip install numpy` and `!pip install opencv-python==4.6.0.66`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a_P1hg9HSXL"
      },
      "source": [
        "### Reading/Writing a Video File"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6iPo_ddHXh6"
      },
      "source": [
        "OpenCV provides the `VideoCapture` and `VideoWriter` classes that support various video file formats. The supported formats vary by system but should always include an AVI. Via its `read()` method, a `VideoCapture` class may be polled for new frames until it reaches the end of its video file. Each frame is an image in a BGR format.\n",
        "\n",
        "Conversely, an image may be passed to the `write()` method of the `VideoWriter` class, which appends the image to a file in VideoWriter. Let's look at an example that reads frames from one AVI file and writes them to another with a YUV encoding:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "c4TmUw_BEeUc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[ WARN:0@18.437] global cap.cpp:779 open VIDEOIO(CV_IMAGES): raised OpenCV exception:\n",
            "\n",
            "OpenCV(4.11.0) /io/opencv/modules/videoio/src/cap_images.cpp:415: error: (-215:Assertion failed) !filename_pattern.empty() in function 'CvVideoWriter_Images'\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "\n",
        "videoCapture = cv2.VideoCapture('MyInputVid.avi')\n",
        "\n",
        "fps = videoCapture.get(cv2.CAP_PROP_FPS)\n",
        "size = (int(videoCapture.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
        "        int(videoCapture.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
        "\n",
        "videoWriter = cv2.VideoWriter(\n",
        "    'MyOutputVid.avi', cv2.VideoWriter_fourcc('I', '4', '2', '0'),\n",
        "    fps, size)\n",
        "\n",
        "success, frame = videoCapture.read()\n",
        "while success: # Loop until there are no more frames\n",
        "  videoWriter.write(frame)\n",
        "  success, frame = videoCapture.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P6hYs7TJwNe"
      },
      "source": [
        "The arguments to the VideoWriter class constructor deserve special attention. A video's filename must be specified. Any preexisting file with this name is overwritten. A video codec must also be specified. The available codecs may vary from system to system. These are the options that are included:\n",
        "* `cv2.VideoWriter_fourcc('I','4','2','0')`: This option is an uncompressed YUV encoding, 4:2:0 chroma subsampled. This encoding is widely compatible but produces large files. The file extension should be .avi.\n",
        "* `cv2.VideoWriter_fourcc('P','I','M','1')`: This option is MPEG-1. The file extension should be .avi.\n",
        "* `cv2.VideoWriter_fourcc('X','V','I','D')`: This option is MPEG-4 and a preferred option if you want the resulting video size to be average. The file\n",
        "extension should be .avi.\n",
        "* `cv2.VideoWriter_fourcc('T','H','E','O')`: This option is Ogg Vorbis. The file extension should be .ogv.\n",
        "* `cv2.VideoWriter_fourcc('F','L','V','1')`: This option is a Flash video. The file extension should be .flv.\n",
        "\n",
        "A frame rate and frame size must be specified too. Since we are copying video frames from another video, these properties can be read from the get() method\n",
        "of the VideoCapture class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YQOlAY8KGZm"
      },
      "source": [
        "### Capturing camera frames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Aex22DkKJG9"
      },
      "source": [
        "A stream of camera frames is represented by the VideoCapture class too. However, for a camera, we construct a VideoCapture class by passing the camera's device index instead of a video's filename. Let's consider an example that captures 10 seconds of video from a camera and writes it to an AVI file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wTDi4mPFK1ud"
      },
      "outputs": [
        {
          "ename": "error",
          "evalue": "OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'VideoWriter'\n> Overload resolution failed:\n>  - Can't parse 'frameSize'. Expected sequence length 2, got 1\n>  - VideoWriter() missing required argument 'frameSize' (pos 5)\n>  - VideoWriter() missing required argument 'params' (pos 5)\n>  - VideoWriter() missing required argument 'frameSize' (pos 5)\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m fps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m \u001b[38;5;66;03m# an assumption\u001b[39;00m\n\u001b[1;32m      6\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(cameraCapture\u001b[38;5;241m.\u001b[39mget(cv2\u001b[38;5;241m.\u001b[39mCAP_PROP_FRAME_WIDTH)),\n\u001b[0;32m----> 8\u001b[0m videoWriter \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVideoWriter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMyOutputVid.avi\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVideoWriter_fourcc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mI\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m success, frame \u001b[38;5;241m=\u001b[39m cameraCapture\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     13\u001b[0m numFramesRemaining \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m*\u001b[39m fps \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'VideoWriter'\n> Overload resolution failed:\n>  - Can't parse 'frameSize'. Expected sequence length 2, got 1\n>  - VideoWriter() missing required argument 'frameSize' (pos 5)\n>  - VideoWriter() missing required argument 'params' (pos 5)\n>  - VideoWriter() missing required argument 'frameSize' (pos 5)\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "\n",
        "cameraCapture = cv2.VideoCapture(0)\n",
        "fps = 30 # an assumption\n",
        "\n",
        "size = int(cameraCapture.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
        "\n",
        "videoWriter = cv2.VideoWriter(\n",
        "    'MyOutputVid.avi', cv2.VideoWriter_fourcc('I', '4', '2', '0'),\n",
        "    fps, size)\n",
        "\n",
        "success, frame = cameraCapture.read()\n",
        "numFramesRemaining = 10 * fps - 1\n",
        "\n",
        "while success and numFramesRemaining > 0:\n",
        "  videoWriter.write(frame)\n",
        "  success, frame = cameraCapture.read()\n",
        "  numFramesRemaining -= 1\n",
        "\n",
        "cameraCapture.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nm43aVOVL8Sr"
      },
      "source": [
        "Unfortunately, the `get()` method of a VideoCapture class does not return an accurate value for the camera's frame rate; it always returns 0. The official\n",
        "documentation at http://docs.opencv.org/modules/highgui/doc/reading_ and_writing_images_and_video.html reads:\n",
        "\n",
        "> \"When querying a property that is not supported by the backend used by the VideoCapture class, value 0 is returned.\"\n",
        "\n",
        "This occurs most commonly on systems where the driver only supports basic functionalities. For the purpose of creating an appropriate VideoWriter class for the camera, we have to either make an assumption about the frame rate (as we did in the code previously) or measure it using a timer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWtfP2CdMh16"
      },
      "source": [
        "The `read()` method is inappropriate when we need to synchronize a set of cameras or a multihead camera (such as a stereo camera or Kinect). Then, we use the `grab()` and `retrieve()` methods instead. For a set of cameras, we use this code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "X8pO75o0Mo9R"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n\\nsuccess0 = cameraCapture0.grab()\\nsuccess1 = cameraCapture1.grab()\\nif success0 and success1:\\n  frame0 = cameraCapture0.retrieve()\\n  frame1 = cameraCapture1.retrieve()\\n\\n'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "\n",
        "success0 = cameraCapture0.grab()\n",
        "success1 = cameraCapture1.grab()\n",
        "if success0 and success1:\n",
        "  frame0 = cameraCapture0.retrieve()\n",
        "  frame1 = cameraCapture1.retrieve()\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RIFMXY7MuGB"
      },
      "source": [
        "### Displaying images in a window"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxLV090lMwPQ"
      },
      "source": [
        "One of the most basic operations in OpenCV is displaying an image. This can be done with the imshow() function. If you come from any other GUI framework\n",
        "background, you would think it sufficient to call imshow() to display an image. This is only partially true: the image will be displayed, and will disappear immediately. This is by design, to enable the constant refreshing of a window frame when working\n",
        "with videos. Here's a very simple example code to display an image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "t-AQAy_eMzp5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/kurty/.pyenvtf/lib/python3.12/site-packages/cv2/qt/plugins\"\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "img = cv2.imread('DaBloat.png')\n",
        "cv2.imshow('DaBloat', img)\n",
        "cv2.waitKey()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4GMdJObM9VQ"
      },
      "source": [
        "The `imshow()` function takes two parameters: the name of the frame in which we want to display the image, and the image itself. We'll talk about `waitKey()` in more detail when we explore the displaying of frames in a window.\n",
        "\n",
        "The aptly named `destroyAllWindows()` function disposes of all the windows created by OpenCV."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuMkv4fKNGoo"
      },
      "source": [
        "### Displaying camera frames in a window"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1_PeWA1NJ7x"
      },
      "source": [
        "OpenCV allows named windows to be created, redrawn, and destroyed using the `namedWindow()`, `imshow()`, and `destroyWindow()` functions. Also, any window may capture keyboard input via the `waitKey()` function and mouse input via the `setMouseCallback()` function. Let's look at an example where we show the frames of a live camera input:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OrBPLsvBNQLg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Showing camera feed. Click window or press any key to stop.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[ WARN:0@36.676] global cap_v4l.cpp:913 open VIDEOIO(V4L2:/dev/video0): can't open camera by index\n",
            "[ERROR:0@36.676] global obsensor_uvc_stream_channel.cpp:158 getStreamChannelGroup Camera index out of range\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "\n",
        "clicked = False\n",
        "\n",
        "def onMouse(event, x, y, flags, param):\n",
        "  global clicked\n",
        "  if event == cv2.EVENT_LBUTTONUP:\n",
        "    clicked = True\n",
        "\n",
        "cameraCapture = cv2.VideoCapture(0)\n",
        "cv2.namedWindow('MyWindow')\n",
        "cv2.setMouseCallback('MyWindow', onMouse)\n",
        "\n",
        "print('Showing camera feed. Click window or press any key to stop.')\n",
        "\n",
        "success, frame = cameraCapture.read()\n",
        "\n",
        "while success and cv2.waitKey(1) == -1 and not clicked:\n",
        "  cv2.imshow('MyWindow', frame)\n",
        "  success, frame = cameraCapture.read()\n",
        "\n",
        "cv2.destroyWindow('MyWindow')\n",
        "cameraCapture.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Sbqf0tMOE0_"
      },
      "source": [
        "The argument for `waitKey()` is a number of milliseconds to wait for keyboard input. The return value is either `-1` (meaning that no key has been pressed) or an ASCII keycode, such as `27` for Esc. For a list of ASCII keycodes, see http://www.asciitable.com/. Also, note that Python provides a standard function, `ord()`, which can convert a character to its ASCII keycode. For example, `ord('a')` returns `97`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpZ3cXeaPKxF"
      },
      "source": [
        "OpenCV's window functions and `waitKey()` are interdependent. OpenCV windows are only updated when `waitKey()` is called, and `waitKey()` only captures input when an OpenCV window has focus.\n",
        "\n",
        "The mouse callback passed to `setMouseCallback()` should take five arguments, as seen in our code sample. The callback's param argument is set as an optional third argument to `setMouseCallback()`. By default, it is 0. The callback's event argument is one of the following actions:\n",
        "\n",
        "* `cv2.EVENT_MOUSEMOVE`: This event refers to mouse movement\n",
        "* `cv2.EVENT_LBUTTONDOWN`: This event refers to the left button down\n",
        "* `cv2.EVENT_RBUTTONDOWN`: This refers to the right button down\n",
        "* `cv2.EVENT_MBUTTONDOWN`: This refers to the middle button down\n",
        "* `cv2.EVENT_LBUTTONUP`: This refers to the left button up\n",
        "* `cv2.EVENT_RBUTTONUP`: This event refers to the right button up\n",
        "* `cv2.EVENT_MBUTTONUP`: This event refers to the middle button up\n",
        "* `cv2.EVENT_LBUTTONDBLCLK`: This event refers to the left button being double-clicked\n",
        "* `cv2.EVENT_RBUTTONDBLCLK`: This refers to the right button being double-clicked\n",
        "* `cv2.EVENT_MBUTTONDBLCLK`: This refers to the middle button being double-clicked"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mac_puc9PpFM"
      },
      "source": [
        "The mouse callback's flags argument may be some bitwise combination of the following events:\n",
        "\n",
        "* `cv2.EVENT_FLAG_LBUTTON`: This event refers to the left button being pressed\n",
        "* `cv2.EVENT_FLAG_RBUTTON`: This event refers to the right button being pressed\n",
        "* `cv2.EVENT_FLAG_MBUTTON`: This event refers to the middle button being pressed\n",
        "* `cv2.EVENT_FLAG_CTRLKEY`: This event refers to the Ctrl key being pressed\n",
        "* `cv2.EVENT_FLAG_SHIFTKEY`: This event refers to the Shift key being pressed\n",
        "* `cv2.EVENT_FLAG_ALTKEY`: This event refers to the Alt key being pressed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ox0ewgrPlCM"
      },
      "source": [
        "Unfortunately, OpenCV does not provide any means of handling window events. For example, we cannot stop our application when a window's close button is\n",
        "clicked. Due to OpenCV's limited event handling and GUI capabilities, many developers prefer to integrate it with other application frameworks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkyd0KjtGl79"
      },
      "source": [
        "## 4. Supplementary Activity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbaLZ7KTQIfT"
      },
      "source": [
        "Perform each of the following tasks.\n",
        "\n",
        "1. Try reading and writing a video file in various formats.\n",
        "2. Similar to activity #1, show an image of your favorite character on a window. Afterwards, slice so that only the character's face is displayed.\n",
        "3. Capture video from your webcam and display on a window. Afterwards, the video should be written as a new file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Try reading and writing a video file in various formats.\n",
        "\n",
        "# Example for MP4 format\n",
        "import cv2\n",
        "\n",
        "cap = cv2.VideoCapture('test1.mp4')\n",
        "\n",
        "if (cap.isOpened()== False):\n",
        "    print(\"Error opening video file\")\n",
        "\n",
        "while(cap.isOpened()):\n",
        "    \n",
        "    ret, frame = cap.read()\n",
        "    if ret == True:\n",
        "    # Display the resulting frame\n",
        "        cv2.imshow('Frame', frame)\n",
        "        \n",
        "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    else:\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Similar to activity #1, show an image of your favorite character on a window.\n",
        "# Afterwards, slice so that only the character's face is displayed.\n",
        "import cv2\n",
        "\n",
        "img = cv2.imread('DaBloat.png')\n",
        "cv2.imshow(\"Face\", img[150:750, 350:750])\n",
        "cv2.waitKey()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Capture video from your webcam and display on a window. \n",
        "# Afterwards, the video should be written as a new file.\n",
        "import cv2\n",
        "\n",
        "record = False\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "if (cap.isOpened() == False): \n",
        "  print(\"Unable to read camera feed\")\n",
        "\n",
        "frame_width = int(cap.get(3))\n",
        "frame_height = int(cap.get(4))\n",
        "\n",
        "out = cv2.VideoWriter('output.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 30, (frame_width,frame_height))\n",
        "\n",
        "while(True):\n",
        "  ret, frame = cap.read()\n",
        "  k = cv2.waitKey(1)\n",
        "\n",
        "  if ret == True: \n",
        "    cv2.imshow('frame',frame)\n",
        "\n",
        "    # press space key to start recording\n",
        "    if k%256 == 32:\n",
        "        record = True\n",
        "\n",
        "    if record:\n",
        "        out.write(frame) \n",
        "\n",
        "    # press q key to close the program\n",
        "    if k & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "  else:\n",
        "     break  \n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NOTE: This activities are done as a python Scripts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQspxP0IGoO1"
      },
      "source": [
        "## 5. Summary, Conclusions and Lessons Learned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvcmGICAoj1a"
      },
      "source": [
        "- In this activity, I learned to utilize the OpenCV that acts as a webcam. As for the last activity, we read and manipulate images using opencv which also the logic to enable videos to be read. The Videos are sliced frame by frame and using the imshow function,  you can see that the frames are loaded continuously thats why we can see it move (as a video). This activity also taught me how to display images and pictures in a window, which is more convenient than plotting the data continuously. In this way als, we can create are very own camera software which we can capture a picture (in just saving a particular frame of the camera feed) or recording a whole video (saving the continuous frames)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqlVIPSqolAC"
      },
      "source": [
        "<hr/>\n",
        "\n",
        "***Proprietary Clause***\n",
        "\n",
        "*Property of the Technological Institute of the Philippines (T.I.P.). No part of the materials made and uploaded in this learning management system by T.I.P. may be copied, photographed, printed, reproduced, shared, transmitted, translated, or reduced to any electronic medium or machine-readable form, in whole or in part, without the prior consent of T.I.P.*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "0a_P1hg9HSXL",
        "_YQOlAY8KGZm",
        "1RIFMXY7MuGB",
        "XuMkv4fKNGoo"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Tensor",
      "language": "python",
      "name": ".pyenvtf"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
